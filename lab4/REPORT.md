# Отчёт по лабораторной работе
## Свёрточные нейронные сети

### Студенты: 

| ФИО       | Роль в проекте                     | Оценка       |
|-----------|------------------------------------|--------------|
| Андреев А. О. | Программировал задание 1, писал отчет |          |
| Семин А. В. | Программировал задание 2, писал отчет |       |
| Попов И. П. | Программировал задание 3, писал отчет |      |

> *Комментарии проверяющего*


## Задание 1.

Необходимо было придумать архитектуру сверточной нейронной сети для классификации изображений. Для работы был выбран Tensorflow.

Архитектура следующая:
[Rescaling + MaxPooling + Relu] *3 + Dropout + Dense + Softmax

Перед обучением выполняется аугментация изображений (отражение относительно оси у, поворот или зум с вероятностью 0.1) и нормировка (приведение всех чисел к интервалу [0; 1].

- Loss - CrossEntropy
- Optimizer - Adam
- LR - 1е-3
- Epochs - 50

Среди различных экспериментов со слоями и различными параметрами полученная нейросеть оказалась наиболее точной.

Полученные метрики:

- Accuracy: 0.62
- top 3 accuracy: 0.85
- Точность бинарной классификации cats VS dogs: 0.94

Графики в зависимости от эпох:
![графики](https://github.com/MAILabs-Edu-2023/ai_lab4-ai-lab-4-andreev-popov-semin/blob/main/images/graphics.png)

Матрица неточностей:

![матрица задание 1](https://github.com/MAILabs-Edu-2023/ai_lab4-ai-lab-4-andreev-popov-semin/blob/main/images/matrix.png)

Лучше всего модель справилась с бинарной классификацией кошек и собак (точность - 0.94). Также заметим, что левая нижняя и правая верхняя части матрицы неточностей почти нулевые.

Определять непосредственно породы кошек и собак модель может не всегда. Имеем точность 0.67. Однако в 88% случаев правильная порода находится в топ 3 предсказаниях модели.

Датасет сейчас не очень большой для каждого класса, поэтому точность предсказаний получилась не очень большой.

## Задание 2.
Здесь необходимо было использовать предобученные модели для классификации собак и кошек по породам. Для работы использован Torch.

Использованы сети VGG-16 и ResNet-18. Обе были предобучены на ImageNet. В каждой сети заменен последний полносвязный слой, чтобы классов на выходе было столько, сколько в данном датасете.

Так как модели предобучены, то они уже неплохо справляются с выделением фичей из картинок. Это значит, что не нужно много эпох на дообучение, поэтому было решено сделать всего 2 эпохи обучения (с увеличением эпох результат особо не изменлялся). Обе сети показали себя примерно одинаково - получили accuracy 0.80 - 0.81.

Графики в зависимости от эпох:

![loss](https://github.com/MAILabs-Edu-2023/ai_lab4-ai-lab-4-andreev-popov-semin/blob/main/images/graph_loss_task2.png)

![accuracy](https://github.com/MAILabs-Edu-2023/ai_lab4-ai-lab-4-andreev-popov-semin/blob/main/images/graph_acc_task2.png)

Матрица неточностей:
![матрица задание 2](https://github.com/MAILabs-Edu-2023/ai_lab4-ai-lab-4-andreev-popov-semin/blob/main/images/matrix_task2.png)

Точность бинарной классификации кошек и собак была "прикинута" из-за невозможности классификации. Случаев, когда нейросеть путает кошек и собак мало - не более 50. Соответсвтенно точность классификации кошек и собак равна ~96%.

## Задание 3.

Необходимо было натренировать генеративную модель для генерации изображений кошек и собак на основе данного датасета. Датасетом был выбран датасет из каггла Oxford Pets.

Генеративные состязательные сети используются для создания изображений, которых раньше никогда не существовало. Они узнают об окружающем мире (предметах, животных и так далее) и создают новые версии тех образов, которые никогда не существовали.

Такие сети состоят из двух компонент:
- Generator - создает новые изображения
- Discriminator - оценивает изображения и сообщает генератору, похожи ли они на то, на чем он был обучен.

При обучении сети и генератор, и дискриминатор начинают обучаются с нуля и вместе.

> Как работает GAN

**G** (Generator) - принимает входной сигнал в виде случайного шумового сигнала и затем выводит изображение.

**D** (Discriminator) - оппонент генератора. Позволяет получать информацию об объектах, животных или других заданных особенностях, классифицировать их.

> Процесс работы
1. Мы вводим случайный шумовой сигнал в генератор. Генератор создает несколько изображений, которые используются для обучения дискриминатора. Мы предоставляем дискриминатору некоторые функции / изображения, которые мы хотим, чтобы он изучил, и дискриминатор выводит вероятности. Эти вероятности могут быть довольно высокими, поскольку дискриминатор только начал обучаться. Затем значения оцениваются и идентифицируются. Вычисляется ошибка, и они передаются обратно через дискриминатор, где обновляются веса.
Далее обучаем генератор. Мы берем пакет изображений, который он создал, и снова пропускаем их через дискриминатор. Мы не включаем полнометражные изображения. Генератор учится, обманывая дискриминатор, выдавая ложные срабатывания. Дискриминатор выдаст выходные данные о вероятностях. Затем значения оцениваются и сравниваются с тем, какими они должны были быть. Ошибка вычисляется и передается обратно через генератор, а веса обновляются.

2. Схож с 1 этапом, но генератор и дискриминатор обучаются немного больше. Благодаря обратному распространению генератор понимает свои ошибки и начинает делать их более похожими на функцию.

## Вывод

В этой работе мы попрактиковались в обучении сверточных нейросетей для классификации изображений. Мы попробовали два подхода: обучение сети с нуля и Transfer Learning. Второй подход, конечно же, оказался более точным из-за инициализации модели весами, полученных после обучения на ImageNet.

Также мы познакомились с фреймворком Tensorflow, на котором до этого не приходилось работать. Оказалось, что это очень удобный инструмент, где большая часть работы уже сделана за нас. Но этот 
фреймворк не очень гибкий по сравнению с Torch.

Также мы познакомились и поработали с генеративной состязательной сетью и использовали ее для генерации новых изображений, однако они получились сильно некрасивыми из-за недостаточного количества эпох для обучения модели, т. к. обучение происходит очень долго.
